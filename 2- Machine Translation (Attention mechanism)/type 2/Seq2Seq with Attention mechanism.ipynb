{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305507d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64bb8d76",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e4eee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Torchtext==0.9 in c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from Torchtext==0.9) (4.62.3)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from Torchtext==0.9) (2.27.1)\n",
      "Requirement already satisfied: torch==1.8.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from Torchtext==0.9) (1.8.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from Torchtext==0.9) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from torch==1.8.0->Torchtext==0.9) (3.10.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from requests->Torchtext==0.9) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from requests->Torchtext==0.9) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from requests->Torchtext==0.9) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from requests->Torchtext==0.9) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from tqdm->Torchtext==0.9) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orchtext (c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orchtext (c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orchtext (c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orchtext (c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orchtext (c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orchtext (c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\programdata\\anaconda3\\envs\\pytorch_env\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install Torchtext==0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d81a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.legacy.datasets import Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82625543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "spacy.cli.download(\"de_core_news_sm\")\n",
    "\n",
    "\n",
    "spacy_ger = spacy.load('de_core_news_sm')\n",
    "spacy_eng = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e188332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_ger(text):\n",
    "    return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
    "\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddafcada",
   "metadata": {},
   "outputs": [],
   "source": [
    "german = Field(tokenize=tokenize_ger, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "english = Field(\n",
    "    tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38193f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(\n",
    "    exts=(\".de\", \".en\"), fields=(german, english)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4caf793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 29000\n",
      "Number of validation examples: 1014\n",
      "Number of testing examples: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa10780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "english.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ae7056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.src),\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "001f959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=True)\n",
    "\n",
    "        self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.fc_cell = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        encoder_states, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "\n",
    "        # Use forward, backward cells and hidden through a linear layer\n",
    "        # so that it can be input to the decoder which is not bidirectional\n",
    "        # Also using index slicing ([idx:idx+1]) to keep the dimension\n",
    "        hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
    "        cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
    "\n",
    "        return encoder_states, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7304540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        # hidden*2 bidirectional...for context vec....+ embedding\n",
    "        self.rnn = nn.LSTM(hidden_size * 2 + embedding_size, hidden_size, num_layers)\n",
    "\n",
    "        self.energy = nn.Linear(hidden_size * 3, 1)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, encoder_states, hidden, cell):\n",
    "        x = x.unsqueeze(0)\n",
    "        # x: (1, N) where N is the batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        sequence_length = encoder_states.shape[0]\n",
    "        h_reshaped = hidden.repeat(sequence_length, 1, 1)\n",
    "        # h_reshaped: (seq_length, N, hidden_size*2)\n",
    "\n",
    "        energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2)))\n",
    "        # energy: (seq_length, N, 1)\n",
    "\n",
    "        attention = self.softmax(energy)\n",
    "        # attention: (seq_length, N, 1)\n",
    "\n",
    "        # attention: (seq_length, N, 1), snk\n",
    "        # encoder_states: (seq_length, N, hidden_size*2), snl\n",
    "        # we want context_vector: (1, N, hidden_size*2), i.e knl\n",
    "        context_vector = torch.einsum(\"snk,snl->knl\", attention, encoder_states)\n",
    "\n",
    "        rnn_input = torch.cat((context_vector, embedding), dim=2)\n",
    "        # rnn_input: (1, N, hidden_size*2 + embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs).squeeze(0)\n",
    "        # predictions: (N, hidden_size)\n",
    "\n",
    "        return predictions, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7284b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(english.vocab)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "        encoder_states, hidden, cell = self.encoder(source)\n",
    "\n",
    "        # First input will be <SOS> token\n",
    "        x = target[0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # At every time step use encoder_states and update hidden, cell\n",
    "            output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n",
    "\n",
    "            # Store prediction for current time step\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            # With probability of teacher_force_ratio we take the actual next word\n",
    "            # otherwise we take the word that the Decoder predicted it to be.\n",
    "            # Teacher Forcing is used so that the model gets used to seeing\n",
    "            # similar inputs at training and testing time, if teacher forcing is 1\n",
    "            # then inputs at test time might be completely different than what the\n",
    "            # network is used to. This was a long comment.\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7cca66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "\n",
    "# Model hyperparameters\n",
    "load_model = False\n",
    "\n",
    "\n",
    "input_size_encoder = len(german.vocab)\n",
    "input_size_decoder = len(english.vocab)\n",
    "output_size = len(english.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024  # Needs to be the same for both RNN's\n",
    "num_layers = 1\n",
    "enc_dropout = 0.0\n",
    "dec_dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14ecd1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard to get nice loss plot\n",
    "writer = SummaryWriter(f\"runs/loss_plot\")\n",
    "step = 0\n",
    "\n",
    "\n",
    "\n",
    "encoder_net = Encoder(\n",
    "    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
    ").to(device)\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout,\n",
    ").to(device)\n",
    "\n",
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfd20e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / 10]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['whisking', 'robes', 'deflated', 'whisking', 'coconut', 'drums', 'motions', 'consults', 'occasion', 'lemon', 'emotion', 'garment', 'shallow', 'sucks', 'spray', 'sweeping', 'final', 'grandfather', 'grandfather', 'trucks', 'cathedral', 'spending', 'maintained', 'creek', 'seated', 'denim', 'fives', 'pressing', 'technician', 'mug', 'dozens', 'brothers', 'pit', 'bearded', 'bib', 'stoop', 'poker', 'drummers', 'piece', 'guitar', 'guitar', 'helped', 'splashes', 'bridesmaid', 'snowing', 'rides', 'trophy', 'hairdo', 'triangle', 'thing']\n",
      "[Epoch 1 / 10]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', '<unk>', 'with', 'a', '<unk>', 'a', 'a', 'large', '<unk>', 'of', 'a', 'large', 'building', '.', '<eos>']\n",
      "[Epoch 2 / 10]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'construction', 'worker', 'with', 'two', 'men', 'being', 'pulled', 'by', 'a', 'large', 'a', 'large', '.', '.', '<eos>']\n",
      "[Epoch 3 / 10]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'boat', 'worker', 'with', 'two', 'men', 'on', 'a', 'large', 'by', 'a', 'large', '.', '<eos>']\n",
      "[Epoch 4 / 10]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'boat', 'with', 'several', 'men', 'being', 'pulled', 'by', 'a', 'large', 'of', 'a', 'large', '.', '<eos>']\n",
      "[Epoch 5 / 10]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'boat', 'boat', 'several', 'men', 'being', 'pulled', 'by', 'by', 'by', 'a', 'large', 'by', 'a', 'large', '.', '<eos>']\n",
      "[Epoch 6 / 10]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'boat', 'with', 'several', 'men', 'being', 'pulled', 'by', 'by', 'a', 'large', 'of', 'of', '.', '<eos>']\n",
      "[Epoch 7 / 10]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'boat', 'carrying', 'several', 'boat', 'being', 'pulled', 'by', 'by', 'large', 'group', 'of', 'horses', 'by', 'a', 'large', 'group', 'of', 'horses', '.', '<eos>']\n",
      "[Epoch 8 / 10]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'boat', 'men', 'with', 'several', 'men', 'being', 'pulled', 'by', 'by', 'a', 'large', 'bull', 'of', 'horses', '.', '<eos>']\n",
      "[Epoch 9 / 10]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'boat', 'carrying', 'several', 'men', 'is', 'being', 'pulled', 'by', 'by', 'a', 'large', 'soccer', 'ball', '.', '<eos>']\n",
      "Bleu score 23.68\n"
     ]
    }
   ],
   "source": [
    "if load_model:\n",
    "    load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\n",
    "\n",
    "\n",
    "sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "    checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "    save_checkpoint(checkpoint)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    translated_sentence = translate_sentence(\n",
    "        model, sentence, german, english, device, max_length=50\n",
    "    )\n",
    "\n",
    "    print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        # Get input and targets and get to cuda\n",
    "        inp_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target)\n",
    "\n",
    "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
    "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
    "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
    "        # way that we have output_words * batch_size that we want to send in into\n",
    "        # our cost function, so we need to do some reshapin. While we're at it\n",
    "        # Let's also remove the start token while we're at it\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Plot to tensorboard\n",
    "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        step += 1\n",
    "\n",
    "\n",
    "score = bleu(test_data[1:100], model, german, english, device)\n",
    "print(f\"Bleu score {score*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4508c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_sentence = 'A man with a blue shirt is running in the street'\n",
    "sentence = 'Ein Mann mit blauem Hemd läuft auf der Straße.'\n",
    "model.eval()\n",
    "s\n",
    "translated_sentence = translate_sentence(\n",
    "    model, sentence, german, english, device, max_length=50)\n",
    "\n",
    "print('Correct English translation: \\n {}'.format(eng_sentence))\n",
    "print(f\"Translation by our machine: \\n {translated_sentence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
